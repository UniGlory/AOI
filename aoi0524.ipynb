{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q7hp6EL0rDf4"
   },
   "source": [
    "使用google drive上傳資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20575,
     "status": "ok",
     "timestamp": 1558671105706,
     "user": {
      "displayName": "呂嘉銘",
      "photoUrl": "",
      "userId": "12693850279873956023"
     },
     "user_tz": -480
    },
    "id": "uEHrJ5lVQMcB",
    "outputId": "dc5b1385-7f32-4171-bb7c-aa4dc52b6635"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2111,
     "status": "ok",
     "timestamp": 1558671113475,
     "user": {
      "displayName": "呂嘉銘",
      "photoUrl": "",
      "userId": "12693850279873956023"
     },
     "user_tz": -480
    },
    "id": "wSE-KUByPPaE",
    "outputId": "29fde923-7ccc-4e1b-ac53-f811e88e8bfd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import merge, Input\n",
    "from keras.models import Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9W4ufCeyDlui"
   },
   "source": [
    "讀取圖片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aPbF9XngPPaJ",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PATH = \"C:\\Users\\user\\Downloads\\Python\\AUAOI\"\n",
    "!ls \"C:\\Users\\user\\Downloads\\Python\\AUAOI\"\n",
    "\n",
    "#寫入資料夾路徑\n",
    "#寫入資料夾目錄下的檔名\n",
    "data_path = PATH + '/AOIdata_100'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "#設定一個list\n",
    "img_data_list=[]\n",
    "\n",
    "#使用雙層for迴圈讀取每一筆圖片檔\n",
    "for dataset in data_dir_list:\n",
    "    img list = os.listdir(data_path+'/'+dataset)\n",
    "    print ('Loaded the images of dataset-'+dataset)\n",
    "    for img in img_list:\n",
    "        img_path = data_path+'/'+dataset+'/'+img\n",
    "    \n",
    "    #讀取圖片\n",
    "    #將讀取到的圖片轉成array\n",
    "    #在陣列最前面增加一個維度\n",
    "    #進行標準化\n",
    "    #把標準化的值存入list\n",
    "img = image.load_img(img_path)\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "img_data_list.append(x)\n",
    "\n",
    "img_data = np.array(img_data_list)\n",
    "\n",
    "print (img_data.shape)  #(600, 1, 224, 224, 3)\n",
    "img_data=np.rollaxis(img_data,1,0)\n",
    "print (img_data.shape)  #(1, 600, 224, 224, 3)\n",
    "img_data=img_data[0]\n",
    "print (img_data.shape)  #(600, 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pG2D4U7_PPaN"
   },
   "outputs": [],
   "source": [
    "# 給每張圖片標上Label\n",
    "num_classes = 6\n",
    "num_of_samples = img_data.shape[0]\n",
    "labels = np.ones((num_of_samples,),dtype='int64')\n",
    "\n",
    "labels[0:100]=0\n",
    "labels[100:200]=1\n",
    "labels[200:300]=2\n",
    "labels[300:400]=3\n",
    "labels[400:500]=4\n",
    "labels[500:600]=5\n",
    "\n",
    "# one-hot encoding\n",
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "#將圖片與Label對應\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "# 切割資料分為訓練(train)跟測試(test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bRH-lm84PPaP",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#設定input shape\n",
    "###  CODE HERE ###  (≈ 1 lines)\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "#取用VGG16模型 include_top為是否保留最上層三層的全連接層\n",
    "#include_top=ture 默認輸入為(224,224,3) 須調整則須改成 False\n",
    "###  CODE HERE ###  (≈ 1 lines)\n",
    "model = VGG16(input_tensor=image_input, include_top=False,weights='imagenet')\n",
    "#輸出模型層數概況\n",
    "###  CODE HERE ###  (≈ 1 lines)\n",
    "model.summary()\n",
    "\n",
    "last_layer = model.get_layer('fc2').output\n",
    "out = Dense(num_classes, activation='softmax', name='output')(last_layer)\n",
    "custom_vgg_model = Model(image_input, out)\n",
    "custom_vgg_model.summary()\n",
    "\n",
    "for layer in custom_vgg_model.layers[:-1]:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "#設定模型的損失函數 優化器 列出準確率\n",
    "###  CODE HERE ###  (≈ 1 lines)\n",
    "custom_vgg_model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "\n",
    "t=time.time()\n",
    "#輸入訓練模型需要的參數\n",
    "hist = custom_vgg_model.fit(X_train, y_train, batch_size=32, epcochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "print('Training time: %s' % time.time())\n",
    "\n",
    "#評估訓練完的模型對測試資料的準確度\n",
    "(loss, accuracy)=custom_vgg_model.evaluate(X_test, y_test, batch_size=10, verbose=1)\n",
    "print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))\n",
    "\n",
    "#預測測試資料\n",
    "#印出預測出的Label值\n",
    "### START CODE HERE ###  (≈ 5 lines)\n",
    "prediction = custom_vgg_model.predict(X_test)\n",
    "predict = np.argmax(prediction,axis=1)\n",
    "ans = np.argmax(y_test,axis=1)\n",
    "print(predict)\n",
    "print(ans)\n",
    "### END CODE HERE ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tw3HIqSKHe1x"
   },
   "source": [
    "輸出loss與acc圖像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2uzapglPPaS"
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "# %matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "# visualizing losses and accuracy\n",
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['acc']\n",
    "val_acc=hist.history['val_acc']\n",
    "xc=range(10)\n",
    "\n",
    "plt.figure(1,figsize=(7,5))\n",
    "plt.plot(xc,train_loss)\n",
    "plt.plot(xc,val_loss)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('train_loss vs val_loss')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'])\n",
    "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])\n",
    "\n",
    "plt.figure(2,figsize=(7,5))\n",
    "plt.plot(xc,train_acc)\n",
    "plt.plot(xc,val_acc)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('train_acc vs val_acc')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'],loc=4)\n",
    "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "thyNqL64GVTk"
   },
   "source": [
    "小練習\n",
    "讀取AOIdata_test中的60張圖片\n",
    "並使用訓練好的模型進行預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GgFbliJBGp6i"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "aoi0524.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
